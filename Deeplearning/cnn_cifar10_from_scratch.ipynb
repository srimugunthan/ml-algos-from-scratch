{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network from Scratch for CIFAR-10\n",
    "\n",
    "This notebook implements a CNN from scratch using PyTorch for CIFAR-10 image classification.\n",
    "\n",
    "## What We'll Build\n",
    "\n",
    "**Dataset: CIFAR-10**\n",
    "- 60,000 color images (32√ó32 pixels)\n",
    "- 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "- 50,000 training images, 10,000 test images\n",
    "\n",
    "**Architecture:**\n",
    "- Convolutional layers (feature extraction)\n",
    "- Pooling layers (downsampling)\n",
    "- Fully connected layers (classification)\n",
    "- Batch normalization (training stability)\n",
    "- Dropout (regularization)\n",
    "\n",
    "**Key Concepts:**\n",
    "1. Convolution: Local feature detection\n",
    "2. Pooling: Spatial invariance\n",
    "3. Feature maps: Hierarchical representations\n",
    "4. Gradient flow through conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 class names\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Data transforms\n",
    "# For training: data augmentation (random crops, flips)\n",
    "# For testing: just normalize\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  # Random crop with padding\n",
    "    transforms.RandomHorizontalFlip(),      # Random horizontal flip\n",
    "    transforms.ToTensor(),                  # Convert to tensor\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),  # Mean of CIFAR-10\n",
    "                        (0.2023, 0.1994, 0.2010))    # Std of CIFAR-10\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                        (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Download and load training data\n",
    "print(\"Downloading CIFAR-10 dataset...\")\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# Download and load test data\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"\\nTraining samples: {len(trainset)}\")\n",
    "print(f\"Test samples: {len(testset)}\")\n",
    "print(f\"Number of classes: {len(classes)}\")\n",
    "print(f\"Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=None):\n",
    "    \"\"\"Display image with denormalization\"\"\"\n",
    "    # Denormalize\n",
    "    img = img * torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "    img = img + torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Get a batch of training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    imshow(images[i], title=classes[labels[i]])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {images[0].shape}  (C √ó H √ó W)\")\n",
    "print(f\"Batch shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build CNN from Scratch\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "```\n",
    "Input: 3√ó32√ó32 RGB image\n",
    "  ‚Üì\n",
    "Conv Block 1: Conv(64) ‚Üí BatchNorm ‚Üí ReLU ‚Üí Pool\n",
    "  32√ó32 ‚Üí 16√ó16\n",
    "  ‚Üì\n",
    "Conv Block 2: Conv(128) ‚Üí BatchNorm ‚Üí ReLU ‚Üí Pool\n",
    "  16√ó16 ‚Üí 8√ó8\n",
    "  ‚Üì\n",
    "Conv Block 3: Conv(256) ‚Üí BatchNorm ‚Üí ReLU ‚Üí Pool\n",
    "  8√ó8 ‚Üí 4√ó4\n",
    "  ‚Üì\n",
    "Flatten: 256√ó4√ó4 = 4096 features\n",
    "  ‚Üì\n",
    "FC Block 1: Linear(512) ‚Üí ReLU ‚Üí Dropout\n",
    "  ‚Üì\n",
    "FC Block 2: Linear(10) ‚Üí Softmax\n",
    "  ‚Üì\n",
    "Output: 10 class probabilities\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for CIFAR-10 classification.\n",
    "    \n",
    "    This is a from-scratch implementation that explicitly shows all layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CIFAR10_CNN, self).__init__()\n",
    "        \n",
    "        # ============================================\n",
    "        # Convolutional Block 1\n",
    "        # Input: 3√ó32√ó32 ‚Üí Output: 64√ó32√ó32 ‚Üí Pool: 64√ó16√ó16\n",
    "        # ============================================\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,      # RGB input\n",
    "            out_channels=64,    # 64 feature maps\n",
    "            kernel_size=3,      # 3√ó3 filter\n",
    "            padding=1           # Same padding to preserve size\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)  # Normalize activations\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Downsample 2√ó\n",
    "        \n",
    "        # ============================================\n",
    "        # Convolutional Block 2\n",
    "        # Input: 64√ó16√ó16 ‚Üí Output: 128√ó16√ó16 ‚Üí Pool: 128√ó8√ó8\n",
    "        # ============================================\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=128,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # ============================================\n",
    "        # Convolutional Block 3\n",
    "        # Input: 128√ó8√ó8 ‚Üí Output: 256√ó8√ó8 ‚Üí Pool: 256√ó4√ó4\n",
    "        # ============================================\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=128,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # ============================================\n",
    "        # Fully Connected Layers\n",
    "        # Flatten: 256√ó4√ó4 = 4096 ‚Üí 512 ‚Üí 10\n",
    "        # ============================================\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Regularization\n",
    "        self.fc2 = nn.Linear(512, 10)  # 10 classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor [batch, 3, 32, 32]\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor [batch, 10]\n",
    "        \"\"\"\n",
    "        # Conv Block 1: 3√ó32√ó32 ‚Üí 64√ó32√ó32 ‚Üí 64√ó16√ó16\n",
    "        x = self.conv1(x)           # Convolution\n",
    "        x = self.bn1(x)             # Batch normalization\n",
    "        x = F.relu(x)               # Activation\n",
    "        x = self.pool1(x)           # Pooling\n",
    "        \n",
    "        # Conv Block 2: 64√ó16√ó16 ‚Üí 128√ó16√ó16 ‚Üí 128√ó8√ó8\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Conv Block 3: 128√ó8√ó8 ‚Üí 256√ó8√ó8 ‚Üí 256√ó4√ó4\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Flatten: 256√ó4√ó4 = 4096\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # FC Block 1: 4096 ‚Üí 512\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # FC Block 2: 512 ‚Üí 10\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Create model instance\n",
    "model = CIFAR10_CNN().to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Forward Pass\n",
    "\n",
    "Let's verify the model works and see the shape transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a small batch\n",
    "test_input = torch.randn(4, 3, 32, 32).to(device)\n",
    "\n",
    "print(\"Testing forward pass...\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Input shape: {test_input.shape}  (batch, channels, height, width)\")\n",
    "\n",
    "# Forward pass with intermediate outputs\n",
    "with torch.no_grad():\n",
    "    # Conv block 1\n",
    "    x = model.pool1(F.relu(model.bn1(model.conv1(test_input))))\n",
    "    print(f\"After Conv Block 1: {x.shape}\")\n",
    "    \n",
    "    # Conv block 2\n",
    "    x = model.pool2(F.relu(model.bn2(model.conv2(x))))\n",
    "    print(f\"After Conv Block 2: {x.shape}\")\n",
    "    \n",
    "    # Conv block 3\n",
    "    x = model.pool3(F.relu(model.bn3(model.conv3(x))))\n",
    "    print(f\"After Conv Block 3: {x.shape}\")\n",
    "    \n",
    "    # Flatten\n",
    "    x = x.view(x.size(0), -1)\n",
    "    print(f\"After Flatten: {x.shape}\")\n",
    "    \n",
    "    # FC layers\n",
    "    x = F.relu(model.fc1(x))\n",
    "    print(f\"After FC1: {x.shape}\")\n",
    "    \n",
    "    output = model.fc2(x)\n",
    "    print(f\"Final output: {output.shape}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úì Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Training Components\n",
    "\n",
    "### Loss Function\n",
    "Cross-Entropy Loss for multi-class classification\n",
    "\n",
    "### Optimizer\n",
    "Adam optimizer with learning rate scheduling\n",
    "\n",
    "### Learning Rate Schedule\n",
    "Reduce learning rate when validation performance plateaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler (reduce LR on plateau)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "print(\"Training components initialized:\")\n",
    "print(f\"  Loss: Cross-Entropy\")\n",
    "print(f\"  Optimizer: Adam (lr=0.001, weight_decay=1e-4)\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train for one epoch.\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss: Average training loss\n",
    "        accuracy: Training accuracy\n",
    "    \"\"\"\n",
    "    model.train()  # Set to training mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(dataloader, desc='Training', leave=False)\n",
    "    \n",
    "    for inputs, labels in pbar:\n",
    "        # Move to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    avg_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on validation/test set.\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss: Average loss\n",
    "        accuracy: Accuracy percentage\n",
    "    \"\"\"\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # No gradients needed\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Track metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    avg_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "print(\"‚úì Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "\n",
    "Training a CNN on CIFAR-10 typically takes:\n",
    "- **CPU:** ~10-15 minutes per epoch\n",
    "- **GPU:** ~30-60 seconds per epoch\n",
    "\n",
    "We'll train for 20 epochs to see good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "n_epochs = 20\n",
    "\n",
    "# Track history\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "best_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss, train_acc = train_epoch(model, trainloader, criterion, optimizer, device)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = evaluate(model, testloader, criterion, device)\n",
    "    \n",
    "    # Update learning rate based on test accuracy\n",
    "    scheduler.step(test_acc)\n",
    "    \n",
    "    # Save history\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    # Track best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'best_cifar10_model.pth')\n",
    "    \n",
    "    # Print epoch summary\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1:2d}/{n_epochs}] ({epoch_time:.1f}s) \"\n",
    "          f\"LR: {current_lr:.6f} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | \"\n",
    "          f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.2f}%\"\n",
    "          f\"{' ‚ÜêBEST' if test_acc == best_acc else ''}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Training completed in {total_time/60:.1f} minutes\")\n",
    "print(f\"Best test accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss curves\n",
    "epochs_range = range(1, n_epochs + 1)\n",
    "axes[0].plot(epochs_range, train_losses, 'o-', label='Train Loss', linewidth=2, markersize=6)\n",
    "axes[0].plot(epochs_range, test_losses, 's-', label='Test Loss', linewidth=2, markersize=6)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Test Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy curves\n",
    "axes[1].plot(epochs_range, train_accs, 'o-', label='Train Accuracy', linewidth=2, markersize=6)\n",
    "axes[1].plot(epochs_range, test_accs, 's-', label='Test Accuracy', linewidth=2, markersize=6)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Test Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0, 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Performance:\")\n",
    "print(f\"  Train Accuracy: {train_accs[-1]:.2f}%\")\n",
    "print(f\"  Test Accuracy:  {test_accs[-1]:.2f}%\")\n",
    "print(f\"  Best Test Acc:  {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Detailed Evaluation\n",
    "\n",
    "Let's analyze per-class performance and visualize predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_cifar10_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Per-class accuracy\n",
    "class_correct = [0] * 10\n",
    "class_total = [0] * 10\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        c = (predicted == labels)\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i].item()\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "# Print per-class accuracy\n",
    "print(\"Per-Class Accuracy:\")\n",
    "print(\"=\" * 50)\n",
    "for i in range(10):\n",
    "    acc = 100 * class_correct[i] / class_total[i]\n",
    "    print(f\"{classes[i]:10s}: {acc:5.2f}% ({class_correct[i]}/{class_total[i]})\")\n",
    "print(\"=\" * 50)\n",
    "overall_acc = 100 * sum(class_correct) / sum(class_total)\n",
    "print(f\"Overall:    {overall_acc:5.2f}% ({sum(class_correct)}/{sum(class_total)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    images_gpu = images.to(device)\n",
    "    outputs = model(images_gpu)\n",
    "    _, predicted = outputs.max(1)\n",
    "    predicted = predicted.cpu()\n",
    "\n",
    "# Plot predictions\n",
    "fig, axes = plt.subplots(3, 6, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(18):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Denormalize and show image\n",
    "    img = images[i]\n",
    "    img = img * torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "    img = img + torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "    # Title with prediction and ground truth\n",
    "    true_label = classes[labels[i]]\n",
    "    pred_label = classes[predicted[i]]\n",
    "    \n",
    "    color = 'green' if predicted[i] == labels[i] else 'red'\n",
    "    ax.set_title(f\"True: {true_label}\\nPred: {pred_label}\", \n",
    "                fontsize=9, color=color, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Sample Predictions (Green=Correct, Red=Wrong)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Learned Filters\n",
    "\n",
    "Let's look at what the first convolutional layer learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first layer weights\n",
    "first_layer_weights = model.conv1.weight.data.cpu()\n",
    "\n",
    "# Plot first 32 filters\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(32):\n",
    "    # Get filter (3 channels, 3x3)\n",
    "    filt = first_layer_weights[i]\n",
    "    \n",
    "    # Normalize for visualization\n",
    "    filt = filt - filt.min()\n",
    "    filt = filt / filt.max()\n",
    "    \n",
    "    # Convert to image format\n",
    "    filt_img = filt.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    axes[i].imshow(filt_img)\n",
    "    axes[i].set_title(f\"Filter {i+1}\", fontsize=8)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('First Layer Convolutional Filters (3√ó3 RGB)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"These filters detect edges, colors, and basic patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize Feature Maps\n",
    "\n",
    "Let's see what features the network extracts from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name, activations):\n",
    "    \"\"\"Hook to capture layer activations\"\"\"\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Get one test image\n",
    "img, label = testset[0]\n",
    "img_input = img.unsqueeze(0).to(device)\n",
    "\n",
    "# Register hooks to capture activations\n",
    "activations = {}\n",
    "model.conv1.register_forward_hook(get_activation('conv1', activations))\n",
    "model.conv2.register_forward_hook(get_activation('conv2', activations))\n",
    "model.conv3.register_forward_hook(get_activation('conv3', activations))\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(img_input)\n",
    "    pred = output.argmax(1).item()\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Original image\n",
    "ax = plt.subplot(3, 9, 1)\n",
    "img_show = img * torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "img_show = img_show + torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "img_show = torch.clamp(img_show, 0, 1)\n",
    "ax.imshow(img_show.permute(1, 2, 0))\n",
    "ax.set_title(f'Original\\n{classes[label]}', fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "# Conv1 feature maps (show first 8)\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(3, 9, i + 2)\n",
    "    feature_map = activations['conv1'][0, i].cpu()\n",
    "    ax.imshow(feature_map, cmap='viridis')\n",
    "    ax.set_title(f'Conv1-{i+1}', fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Conv2 feature maps (show first 9)\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 9, i + 10)\n",
    "    feature_map = activations['conv2'][0, i].cpu()\n",
    "    ax.imshow(feature_map, cmap='viridis')\n",
    "    ax.set_title(f'Conv2-{i+1}', fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Conv3 feature maps (show first 9)\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 9, i + 19)\n",
    "    feature_map = activations['conv3'][0, i].cpu()\n",
    "    ax.imshow(feature_map, cmap='viridis')\n",
    "    ax.set_title(f'Conv3-{i+1}', fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(f'Feature Maps at Different Layers (Predicted: {classes[pred]})', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how:\")\n",
    "print(\"  - Conv1: Detects edges and simple patterns\")\n",
    "print(\"  - Conv2: Combines features into more complex shapes\")\n",
    "print(\"  - Conv3: Creates high-level abstract representations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Concepts in CNNs\n",
    "\n",
    "### 1. Convolutional Layers\n",
    "**Purpose:** Extract local features using learnable filters\n",
    "- **Filter/Kernel:** Small matrix (e.g., 3√ó3) that slides over input\n",
    "- **Convolution operation:** Element-wise multiply + sum\n",
    "- **Feature maps:** Output of applying filters\n",
    "- **Parameter sharing:** Same filter used across entire image\n",
    "\n",
    "**Math:**\n",
    "```\n",
    "Output[i,j] = Œ£ Œ£ Input[i+m, j+n] √ó Filter[m,n] + bias\n",
    "```\n",
    "\n",
    "### 2. Pooling Layers\n",
    "**Purpose:** Downsample to reduce spatial dimensions\n",
    "- **Max pooling:** Take maximum value in window\n",
    "- **Reduces overfitting:** Less parameters\n",
    "- **Translation invariance:** Small shifts don't change output\n",
    "\n",
    "### 3. Batch Normalization\n",
    "**Purpose:** Stabilize training\n",
    "- Normalize activations to mean=0, std=1\n",
    "- Allows higher learning rates\n",
    "- Reduces internal covariate shift\n",
    "\n",
    "### 4. Dropout\n",
    "**Purpose:** Prevent overfitting\n",
    "- Randomly \"drop\" neurons during training\n",
    "- Forces network to learn robust features\n",
    "- Creates ensemble effect\n",
    "\n",
    "### 5. Why CNNs Work for Images\n",
    "- **Local connectivity:** Pixels near each other are related\n",
    "- **Parameter sharing:** Same features appear everywhere\n",
    "- **Translation equivariance:** Shift input ‚Üí shift output\n",
    "- **Hierarchical features:** Low ‚Üí mid ‚Üí high level\n",
    "\n",
    "### Our Architecture Achieved:\n",
    "- ~75-85% accuracy on CIFAR-10 (depending on training)\n",
    "- State-of-the-art: ~95%+ (with deeper networks, data augmentation)\n",
    "- Our model: ~600K parameters\n",
    "- Modern networks: 10M-100M+ parameters\n",
    "\n",
    "### Next Steps to Improve:\n",
    "1. **Deeper network:** More conv layers\n",
    "2. **Residual connections:** Skip connections (ResNet)\n",
    "3. **Data augmentation:** More transforms\n",
    "4. **Better optimization:** Cosine annealing, warmup\n",
    "5. **Regularization:** Mixup, CutMix, label smoothing\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations! You've built a CNN from scratch and understand how it works! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
