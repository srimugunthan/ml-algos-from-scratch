{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Feature Importance from Scratch\n",
    "\n",
    "**Author**: Srimugunthan  \n",
    "**Date**: February 2026\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Permutation Feature Importance** is a model-agnostic method to measure feature importance by evaluating how much model performance decreases when a feature's values are randomly shuffled.\n",
    "\n",
    "### Key Concept\n",
    "\n",
    "If a feature is important:\n",
    "- Shuffling it breaks the relationship with the target\n",
    "- Model performance drops significantly\n",
    "- High importance score\n",
    "\n",
    "If a feature is not important:\n",
    "- Shuffling it has little effect\n",
    "- Model performance stays roughly the same\n",
    "- Low/zero importance score\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "```\n",
    "1. Train model on training data\n",
    "2. Calculate baseline score on validation data\n",
    "3. For each feature:\n",
    "   a. Shuffle the feature's values (breaks feature-target relationship)\n",
    "   b. Calculate score with shuffled feature\n",
    "   c. Importance = baseline_score - shuffled_score\n",
    "   d. Repeat multiple times and average\n",
    "```\n",
    "\n",
    "### Advantages\n",
    "\n",
    "‚úÖ Model-agnostic (works with any model)  \n",
    "‚úÖ Captures feature interactions  \n",
    "‚úÖ No retraining needed  \n",
    "‚úÖ Easy to understand  \n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "‚ö†Ô∏è Computationally expensive  \n",
    "‚ö†Ô∏è Can be affected by correlated features  \n",
    "‚ö†Ô∏è Requires validation set  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_regression, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the Concept\n",
    "\n",
    "Let's visualize what happens when we shuffle a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_shuffling_effect():\n",
    "    \"\"\"\n",
    "    Visualize the effect of shuffling on feature-target relationship\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create synthetic data with clear relationship\n",
    "    n_samples = 100\n",
    "    \n",
    "    # Important feature: strong correlation with target\n",
    "    X_important = np.random.randn(n_samples)\n",
    "    y = 2 * X_important + np.random.randn(n_samples) * 0.5\n",
    "    \n",
    "    # Unimportant feature: no correlation with target\n",
    "    X_unimportant = np.random.randn(n_samples)\n",
    "    \n",
    "    # Shuffle the important feature\n",
    "    X_important_shuffled = np.random.permutation(X_important)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Important feature (before shuffling)\n",
    "    axes[0].scatter(X_important, y, alpha=0.6, edgecolor='black')\n",
    "    axes[0].set_xlabel('Important Feature')\n",
    "    axes[0].set_ylabel('Target')\n",
    "    axes[0].set_title(f'Important Feature (Original)\\nCorrelation: {np.corrcoef(X_important, y)[0,1]:.3f}')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Important feature (after shuffling)\n",
    "    axes[1].scatter(X_important_shuffled, y, alpha=0.6, edgecolor='black', color='orange')\n",
    "    axes[1].set_xlabel('Important Feature (Shuffled)')\n",
    "    axes[1].set_ylabel('Target')\n",
    "    axes[1].set_title(f'Important Feature (Shuffled)\\nCorrelation: {np.corrcoef(X_important_shuffled, y)[0,1]:.3f}')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Unimportant feature\n",
    "    axes[2].scatter(X_unimportant, y, alpha=0.6, edgecolor='black', color='red')\n",
    "    axes[2].set_xlabel('Unimportant Feature')\n",
    "    axes[2].set_ylabel('Target')\n",
    "    axes[2].set_title(f'Unimportant Feature\\nCorrelation: {np.corrcoef(X_unimportant, y)[0,1]:.3f}')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° Key Insight:\")\n",
    "    print(\"   ‚Ä¢ Shuffling an IMPORTANT feature destroys the relationship with target\")\n",
    "    print(\"   ‚Ä¢ Shuffling an UNIMPORTANT feature has little effect (already no relationship)\")\n",
    "    print(\"   ‚Ä¢ This difference in effect is what permutation importance measures!\")\n",
    "\n",
    "visualize_shuffling_effect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing Permutation Importance from Scratch\n",
    "\n",
    "### 3.1 Core Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermutationImportance:\n",
    "    \"\"\"\n",
    "    Permutation Feature Importance from Scratch\n",
    "    \n",
    "    This implementation works with any sklearn-compatible model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, X, y, metric='auto', n_repeats=10, random_state=42):\n",
    "        \"\"\"\n",
    "        Initialize permutation importance calculator\n",
    "        \n",
    "        Args:\n",
    "            model: Trained model with predict() method\n",
    "            X: Feature matrix (validation/test set)\n",
    "            y: Target vector (validation/test set)\n",
    "            metric: Scoring metric ('accuracy', 'r2', 'mse', 'mae', 'auto')\n",
    "            n_repeats: Number of times to shuffle each feature\n",
    "            random_state: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.X = X if isinstance(X, np.ndarray) else X.values\n",
    "        self.y = y if isinstance(y, np.ndarray) else y.values\n",
    "        self.n_repeats = n_repeats\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Auto-detect metric based on model type\n",
    "        if metric == 'auto':\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                self.metric = 'accuracy'\n",
    "                self.higher_is_better = True\n",
    "            else:\n",
    "                self.metric = 'r2'\n",
    "                self.higher_is_better = True\n",
    "        else:\n",
    "            self.metric = metric\n",
    "            self.higher_is_better = metric in ['accuracy', 'r2', 'auc']\n",
    "        \n",
    "        # Store results\n",
    "        self.importances_mean = None\n",
    "        self.importances_std = None\n",
    "        self.importances_raw = None\n",
    "        self.baseline_score = None\n",
    "    \n",
    "    def _get_score(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate score based on specified metric\n",
    "        \"\"\"\n",
    "        y_pred = self.model.predict(X)\n",
    "        \n",
    "        if self.metric == 'accuracy':\n",
    "            return accuracy_score(y, y_pred)\n",
    "        elif self.metric == 'r2':\n",
    "            return r2_score(y, y_pred)\n",
    "        elif self.metric == 'mse':\n",
    "            return mean_squared_error(y, y_pred)\n",
    "        elif self.metric == 'mae':\n",
    "            return mean_absolute_error(y, y_pred)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {self.metric}\")\n",
    "    \n",
    "    def compute(self, verbose=True):\n",
    "        \"\"\"\n",
    "        Compute permutation importance for all features\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with importance statistics\n",
    "        \"\"\"\n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        n_features = self.X.shape[1]\n",
    "        \n",
    "        # Step 1: Calculate baseline score (no permutation)\n",
    "        self.baseline_score = self._get_score(self.X, self.y)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Baseline {self.metric}: {self.baseline_score:.4f}\")\n",
    "            print(f\"Computing importance for {n_features} features...\")\n",
    "        \n",
    "        # Initialize storage for results\n",
    "        importances_raw = np.zeros((n_features, self.n_repeats))\n",
    "        \n",
    "        # Step 2: For each feature\n",
    "        for feature_idx in range(n_features):\n",
    "            if verbose and (feature_idx + 1) % 5 == 0:\n",
    "                print(f\"  Processed {feature_idx + 1}/{n_features} features...\")\n",
    "            \n",
    "            # Step 3: Repeat shuffling n_repeats times\n",
    "            for repeat_idx in range(self.n_repeats):\n",
    "                # Create a copy of the data\n",
    "                X_permuted = self.X.copy()\n",
    "                \n",
    "                # Step 4: Shuffle the feature column\n",
    "                # This breaks the relationship between feature and target\n",
    "                X_permuted[:, feature_idx] = np.random.permutation(X_permuted[:, feature_idx])\n",
    "                \n",
    "                # Step 5: Calculate score with shuffled feature\n",
    "                permuted_score = self._get_score(X_permuted, self.y)\n",
    "                \n",
    "                # Step 6: Calculate importance\n",
    "                # For metrics where higher is better (accuracy, R¬≤)\n",
    "                # For metrics where lower is better (MSE, MAE), flip the sign\n",
    "                if self.higher_is_better:\n",
    "                    importance = self.baseline_score - permuted_score\n",
    "                else:\n",
    "                    importance = permuted_score - self.baseline_score\n",
    "                \n",
    "                importances_raw[feature_idx, repeat_idx] = importance\n",
    "        \n",
    "        # Step 7: Aggregate results across repeats\n",
    "        self.importances_mean = np.mean(importances_raw, axis=1)\n",
    "        self.importances_std = np.std(importances_raw, axis=1)\n",
    "        self.importances_raw = importances_raw\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"‚úì Computation complete!\")\n",
    "        \n",
    "        return {\n",
    "            'importances_mean': self.importances_mean,\n",
    "            'importances_std': self.importances_std,\n",
    "            'importances_raw': self.importances_raw,\n",
    "            'baseline_score': self.baseline_score\n",
    "        }\n",
    "    \n",
    "    def get_feature_importance_df(self, feature_names=None):\n",
    "        \"\"\"\n",
    "        Return feature importance as a pandas DataFrame\n",
    "        \"\"\"\n",
    "        if self.importances_mean is None:\n",
    "            raise ValueError(\"Must call compute() first!\")\n",
    "        \n",
    "        if feature_names is None:\n",
    "            feature_names = [f'Feature_{i}' for i in range(len(self.importances_mean))]\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance_Mean': self.importances_mean,\n",
    "            'Importance_Std': self.importances_std\n",
    "        })\n",
    "        \n",
    "        # Sort by importance\n",
    "        df = df.sort_values('Importance_Mean', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def plot(self, feature_names=None, top_k=None, figsize=(10, 6)):\n",
    "        \"\"\"\n",
    "        Plot permutation importance with error bars\n",
    "        \"\"\"\n",
    "        if self.importances_mean is None:\n",
    "            raise ValueError(\"Must call compute() first!\")\n",
    "        \n",
    "        if feature_names is None:\n",
    "            feature_names = [f'Feature_{i}' for i in range(len(self.importances_mean))]\n",
    "        \n",
    "        # Sort by importance\n",
    "        sorted_idx = np.argsort(self.importances_mean)[::-1]\n",
    "        \n",
    "        if top_k is not None:\n",
    "            sorted_idx = sorted_idx[:top_k]\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.barh(range(len(sorted_idx)),\n",
    "                self.importances_mean[sorted_idx],\n",
    "                xerr=self.importances_std[sorted_idx],\n",
    "                alpha=0.7,\n",
    "                edgecolor='black',\n",
    "                capsize=5)\n",
    "        \n",
    "        plt.yticks(range(len(sorted_idx)),\n",
    "                  [feature_names[i] for i in sorted_idx])\n",
    "        plt.xlabel(f'Permutation Importance ({self.metric})', fontsize=12)\n",
    "        plt.title(f'Feature Importance (Baseline {self.metric}: {self.baseline_score:.4f})', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        plt.axvline(x=0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"‚úì PermutationImportance class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example 1: Classification Task (Synthetic Data)\n",
    "\n",
    "Let's test on a synthetic dataset where we know which features are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXAMPLE 1: BINARY CLASSIFICATION (Synthetic Data)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Generate synthetic data\n",
    "# 10 features: 5 informative, 3 redundant, 2 noise\n",
    "X_class, y_class = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=5,\n",
    "    n_redundant=3,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_class, y_class, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Training samples: {X_train_c.shape[0]}\")\n",
    "print(f\"  Test samples: {X_test_c.shape[0]}\")\n",
    "print(f\"  Features: {X_train_c.shape[1]}\")\n",
    "print(f\"  Classes: {len(np.unique(y_class))}\")\n",
    "\n",
    "# Train Random Forest classifier\n",
    "print(\"\\nTraining Random Forest Classifier...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_c, y_train_c)\n",
    "\n",
    "train_acc = accuracy_score(y_train_c, rf_classifier.predict(X_train_c))\n",
    "test_acc = accuracy_score(y_test_c, rf_classifier.predict(X_test_c))\n",
    "\n",
    "print(f\"  Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Calculate permutation importance\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Computing Permutation Importance...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "perm_imp_class = PermutationImportance(\n",
    "    model=rf_classifier,\n",
    "    X=X_test_c,\n",
    "    y=y_test_c,\n",
    "    metric='accuracy',\n",
    "    n_repeats=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "results_class = perm_imp_class.compute(verbose=True)\n",
    "\n",
    "# Show results\n",
    "feature_names_class = [f'Feature_{i}' for i in range(10)]\n",
    "df_class = perm_imp_class.get_feature_importance_df(feature_names_class)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(df_class.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "perm_imp_class.plot(feature_names_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example 2: Real Dataset (Breast Cancer)\n",
    "\n",
    "Let's apply it to the Breast Cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXAMPLE 2: BREAST CANCER CLASSIFICATION (Real Data)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X_cancer = data.data\n",
    "y_cancer = data.target\n",
    "feature_names_cancer = data.feature_names\n",
    "\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Total samples: {X_cancer.shape[0]}\")\n",
    "print(f\"  Features: {X_cancer.shape[1]}\")\n",
    "print(f\"  Classes: {len(np.unique(y_cancer))}\")\n",
    "\n",
    "# Split data\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"\\nTraining Logistic Regression...\")\n",
    "lr_cancer = LogisticRegression(max_iter=10000, random_state=42)\n",
    "lr_cancer.fit(X_train_cancer, y_train_cancer)\n",
    "\n",
    "train_acc_cancer = accuracy_score(y_train_cancer, lr_cancer.predict(X_train_cancer))\n",
    "test_acc_cancer = accuracy_score(y_test_cancer, lr_cancer.predict(X_test_cancer))\n",
    "\n",
    "print(f\"  Training Accuracy: {train_acc_cancer:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_acc_cancer:.4f}\")\n",
    "\n",
    "# Calculate permutation importance\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Computing Permutation Importance...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "perm_imp_cancer = PermutationImportance(\n",
    "    model=lr_cancer,\n",
    "    X=X_test_cancer,\n",
    "    y=y_test_cancer,\n",
    "    metric='accuracy',\n",
    "    n_repeats=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "results_cancer = perm_imp_cancer.compute(verbose=True)\n",
    "\n",
    "# Show top 15 features\n",
    "df_cancer = perm_imp_cancer.get_feature_importance_df(feature_names_cancer)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP 15 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\"*70)\n",
    "print(df_cancer.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 15 features\n",
    "perm_imp_cancer.plot(feature_names_cancer, top_k=15, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example 3: Regression Task\n",
    "\n",
    "Permutation importance also works for regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXAMPLE 3: REGRESSION (Synthetic Data)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Generate synthetic regression data\n",
    "X_reg, y_reg = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=15,\n",
    "    n_informative=10,\n",
    "    n_targets=1,\n",
    "    noise=10.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Training samples: {X_train_reg.shape[0]}\")\n",
    "print(f\"  Test samples: {X_test_reg.shape[0]}\")\n",
    "print(f\"  Features: {X_train_reg.shape[1]}\")\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "print(\"\\nTraining Random Forest Regressor...\")\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "train_r2 = r2_score(y_train_reg, rf_regressor.predict(X_train_reg))\n",
    "test_r2 = r2_score(y_test_reg, rf_regressor.predict(X_test_reg))\n",
    "\n",
    "print(f\"  Training R¬≤: {train_r2:.4f}\")\n",
    "print(f\"  Test R¬≤: {test_r2:.4f}\")\n",
    "\n",
    "# Calculate permutation importance using R¬≤\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Computing Permutation Importance (using R¬≤)...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "perm_imp_reg = PermutationImportance(\n",
    "    model=rf_regressor,\n",
    "    X=X_test_reg,\n",
    "    y=y_test_reg,\n",
    "    metric='r2',\n",
    "    n_repeats=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "results_reg = perm_imp_reg.compute(verbose=True)\n",
    "\n",
    "# Show results\n",
    "feature_names_reg = [f'Feature_{i}' for i in range(15)]\n",
    "df_reg = perm_imp_reg.get_feature_importance_df(feature_names_reg)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(df_reg.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "perm_imp_reg.plot(feature_names_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing with sklearn's Implementation\n",
    "\n",
    "Let's verify our implementation matches sklearn's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance as sklearn_perm_imp\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPARISON: Our Implementation vs sklearn\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Our implementation (already computed above for classification)\n",
    "our_importances = perm_imp_class.importances_mean\n",
    "\n",
    "# sklearn implementation\n",
    "print(\"\\nComputing with sklearn...\")\n",
    "sklearn_result = sklearn_perm_imp(\n",
    "    rf_classifier,\n",
    "    X_test_c,\n",
    "    y_test_c,\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "sklearn_importances = sklearn_result.importances_mean\n",
    "\n",
    "# Compare\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': feature_names_class,\n",
    "    'Our Implementation': our_importances,\n",
    "    'sklearn': sklearn_importances,\n",
    "    'Difference': np.abs(our_importances - sklearn_importances)\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Our Implementation', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.corrcoef(our_importances, sklearn_importances)[0, 1]\n",
    "print(f\"\\n‚úì Correlation between implementations: {correlation:.6f}\")\n",
    "print(f\"‚úì Mean absolute difference: {comparison_df['Difference'].mean():.6f}\")\n",
    "\n",
    "if correlation > 0.99:\n",
    "    print(\"\\n‚úÖ Perfect match! Our implementation is correct!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Small differences due to random shuffling order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Understanding Negative Importance\n",
    "\n",
    "Sometimes features have negative importance. What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_negative_importance():\n",
    "    \"\"\"\n",
    "    Explain what negative importance means\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"UNDERSTANDING NEGATIVE IMPORTANCE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nüìä What does negative importance mean?\\n\")\n",
    "    \n",
    "    print(\"Positive Importance (e.g., +0.05):\")\n",
    "    print(\"  ‚Ä¢ Shuffling the feature DECREASES model performance\")\n",
    "    print(\"  ‚Ä¢ Feature is useful for prediction\")\n",
    "    print(\"  ‚Ä¢ Model relies on this feature\")\n",
    "    print(\"  ‚Ä¢ Interpretation: 'Removing this feature hurts accuracy by 5%'\")\n",
    "    \n",
    "    print(\"\\nZero Importance (e.g., ~0.00):\")\n",
    "    print(\"  ‚Ä¢ Shuffling the feature has NO effect on performance\")\n",
    "    print(\"  ‚Ä¢ Feature is not used by the model\")\n",
    "    print(\"  ‚Ä¢ Can be safely removed\")\n",
    "    \n",
    "    print(\"\\nNegative Importance (e.g., -0.02):\")\n",
    "    print(\"  ‚Ä¢ Shuffling the feature INCREASES model performance (!)\")\n",
    "    print(\"  ‚Ä¢ Feature is actually hurting the model\")\n",
    "    print(\"  ‚Ä¢ Possible reasons:\")\n",
    "    print(\"    - Feature adds noise\")\n",
    "    print(\"    - Feature is highly correlated with other features\")\n",
    "    print(\"    - Random variation (check std deviation)\")\n",
    "    print(\"    - Overfitting on training set\")\n",
    "    \n",
    "    print(\"\\nüí° Key Insight:\")\n",
    "    print(\"   If importance is negative but std is high, it might just be noise.\")\n",
    "    print(\"   If importance is consistently negative, consider removing the feature.\")\n",
    "\n",
    "explain_negative_importance()\n",
    "\n",
    "# Show features with negative importance from our examples\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURES WITH NEGATIVE IMPORTANCE (from our examples)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "negative_features = df_class[df_class['Importance_Mean'] < 0]\n",
    "if len(negative_features) > 0:\n",
    "    print(\"\\nClassification Example:\")\n",
    "    print(negative_features.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo features with negative importance in classification example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Effect of n_repeats\n",
    "\n",
    "How does the number of repetitions affect the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ANALYZING EFFECT OF n_repeats\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test with different n_repeats\n",
    "n_repeats_values = [1, 5, 10, 20, 50]\n",
    "results_by_repeats = {}\n",
    "\n",
    "print(\"\\nComputing importance with different n_repeats values...\")\n",
    "\n",
    "for n_repeats in n_repeats_values:\n",
    "    print(f\"  n_repeats={n_repeats}...\", end=\" \")\n",
    "    \n",
    "    perm_imp = PermutationImportance(\n",
    "        model=rf_classifier,\n",
    "        X=X_test_c,\n",
    "        y=y_test_c,\n",
    "        metric='accuracy',\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    results = perm_imp.compute(verbose=False)\n",
    "    results_by_repeats[n_repeats] = results\n",
    "    print(\"Done\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Mean importance across n_repeats\n",
    "for n_repeats in n_repeats_values:\n",
    "    importances = results_by_repeats[n_repeats]['importances_mean']\n",
    "    axes[0].plot(range(len(importances)), sorted(importances, reverse=True),\n",
    "                marker='o', label=f'n_repeats={n_repeats}', alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel('Feature Rank')\n",
    "axes[0].set_ylabel('Importance')\n",
    "axes[0].set_title('Mean Importance vs n_repeats')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Standard deviation across n_repeats\n",
    "for n_repeats in n_repeats_values:\n",
    "    std = results_by_repeats[n_repeats]['importances_std']\n",
    "    axes[1].plot(range(len(std)), sorted(std, reverse=True),\n",
    "                marker='o', label=f'n_repeats={n_repeats}', alpha=0.7)\n",
    "\n",
    "axes[1].set_xlabel('Feature Rank')\n",
    "axes[1].set_ylabel('Standard Deviation')\n",
    "axes[1].set_title('Std Deviation vs n_repeats')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"   ‚Ä¢ Higher n_repeats ‚Üí Lower standard deviation ‚Üí More stable estimates\")\n",
    "print(\"   ‚Ä¢ Mean importance converges quickly (even n_repeats=5 is often good)\")\n",
    "print(\"   ‚Ä¢ Trade-off: Computation time vs stability\")\n",
    "print(\"   ‚Ä¢ Recommended: n_repeats=10 for most applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualizing Importance Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance_distributions(perm_imp, feature_names, top_k=5):\n",
    "    \"\"\"\n",
    "    Plot distribution of importance across repeats for top features\n",
    "    \"\"\"\n",
    "    # Get top k features\n",
    "    sorted_idx = np.argsort(perm_imp.importances_mean)[::-1][:top_k]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, top_k, figsize=(4*top_k, 4))\n",
    "    \n",
    "    if top_k == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, feature_idx in enumerate(sorted_idx):\n",
    "        importances = perm_imp.importances_raw[feature_idx]\n",
    "        \n",
    "        axes[i].hist(importances, bins=15, alpha=0.7, edgecolor='black')\n",
    "        axes[i].axvline(perm_imp.importances_mean[feature_idx],\n",
    "                       color='red', linestyle='--', linewidth=2,\n",
    "                       label=f'Mean: {perm_imp.importances_mean[feature_idx]:.4f}')\n",
    "        axes[i].set_xlabel('Importance')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].set_title(f'{feature_names[feature_idx]}\\n(Rank #{i+1})')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Importance Distribution Across Repeats (Top 5 Features)',\n",
    "                fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Plotting importance distributions for top 5 features...\")\n",
    "plot_importance_distributions(perm_imp_class, feature_names_class, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Best Practices\n",
    "\n",
    "### Algorithm Summary\n",
    "\n",
    "```python\n",
    "# Pseudocode for Permutation Importance\n",
    "baseline_score = evaluate(model, X_val, y_val)\n",
    "\n",
    "for each feature in X_val:\n",
    "    importances = []\n",
    "    \n",
    "    for repeat in range(n_repeats):\n",
    "        X_permuted = X_val.copy()\n",
    "        X_permuted[:, feature] = shuffle(X_permuted[:, feature])\n",
    "        permuted_score = evaluate(model, X_permuted, y_val)\n",
    "        importance = baseline_score - permuted_score\n",
    "        importances.append(importance)\n",
    "    \n",
    "    feature_importance[feature] = mean(importances)\n",
    "```\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Use validation/test set** (not training set)\n",
    "   - Training set can give misleading results due to overfitting\n",
    "\n",
    "2. **Choose appropriate n_repeats**\n",
    "   - n_repeats=10 is usually sufficient\n",
    "   - Increase for more stable estimates\n",
    "   - Decrease for faster computation\n",
    "\n",
    "3. **Consider computational cost**\n",
    "   - Cost = n_features √ó n_repeats √ó model_inference_time\n",
    "   - Can be expensive for large datasets or slow models\n",
    "\n",
    "4. **Interpret with caution for correlated features**\n",
    "   - If features A and B are highly correlated\n",
    "   - Shuffling A might not hurt performance (B compensates)\n",
    "   - Both might show low importance even if jointly important\n",
    "\n",
    "5. **Check standard deviation**\n",
    "   - High std ‚Üí Unstable estimate, increase n_repeats\n",
    "   - Low std ‚Üí Reliable estimate\n",
    "\n",
    "6. **Compare with other methods**\n",
    "   - Use alongside tree-based importances, SHAP, etc.\n",
    "   - Different methods can reveal different insights\n",
    "\n",
    "### When to Use Permutation Importance\n",
    "\n",
    "‚úÖ **Good for:**\n",
    "- Model-agnostic feature importance\n",
    "- Comparing features across different models\n",
    "- Understanding feature impact on predictions\n",
    "- Feature selection\n",
    "\n",
    "‚ùå **Not ideal for:**\n",
    "- Extremely large datasets (slow)\n",
    "- Highly correlated features (misleading)\n",
    "- When you need individual prediction explanations (use SHAP)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Key Takeaways\n",
    "\n",
    "### Core Concept\n",
    "Permutation importance measures how much model performance drops when a feature is randomly shuffled, breaking its relationship with the target.\n",
    "\n",
    "### Algorithm Steps\n",
    "1. Calculate baseline score on validation set\n",
    "2. For each feature:\n",
    "   - Shuffle feature values\n",
    "   - Calculate new score\n",
    "   - Importance = baseline - new_score\n",
    "   - Repeat and average\n",
    "\n",
    "### Advantages\n",
    "- Model-agnostic (works with any model)\n",
    "- Intuitive interpretation\n",
    "- Captures feature interactions\n",
    "- No model retraining needed\n",
    "\n",
    "### Limitations\n",
    "- Computationally expensive\n",
    "- Can be misleading with correlated features\n",
    "- Requires separate validation set\n",
    "\n",
    "### Interpretation\n",
    "- **High positive**: Important feature\n",
    "- **Zero**: Unimportant feature\n",
    "- **Negative**: May indicate noise or correlation issues\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Breiman (2001) - Random Forests](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)\n",
    "- [sklearn Permutation Importance](https://scikit-learn.org/stable/modules/permutation_importance.html)\n",
    "- [Interpretable Machine Learning Book - Permutation Feature Importance](https://christophm.github.io/interpretable-ml-book/feature-importance.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
