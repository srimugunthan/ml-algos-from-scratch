{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Isolation Forest Implementation\n",
    "\n",
    "This notebook contains a bare-bones implementation of Isolation Forest for anomaly detection.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **Random splits**: Each tree randomly picks features and split values\n",
    "2. **Path length**: Anomalies are isolated faster (shorter paths)\n",
    "3. **Ensemble**: Average across many trees for robustness\n",
    "4. **Scoring**: Shorter average path = higher anomaly score\n",
    "\n",
    "**The intuition**: Outliers are rare and different, so random splits isolate them quickly near the root of the tree. Normal points take longer to isolate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Isolation Tree Class\n",
    "\n",
    "A single isolation tree that recursively splits data using random features and random thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationTree:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.split_feature = None\n",
    "        self.split_value = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.size = 0\n",
    "        \n",
    "    def fit(self, X, depth=0):\n",
    "        self.size = len(X)\n",
    "        \n",
    "        # Stop if max depth reached or only one sample\n",
    "        if depth >= self.max_depth or len(X) <= 1:\n",
    "            return self\n",
    "        \n",
    "        # Randomly pick a feature and split value\n",
    "        n_features = X.shape[1]\n",
    "        self.split_feature = np.random.randint(0, n_features)\n",
    "        \n",
    "        col_data = X[:, self.split_feature]\n",
    "        min_val, max_val = col_data.min(), col_data.max()\n",
    "        \n",
    "        # Stop if all values are the same\n",
    "        if min_val == max_val:\n",
    "            return self\n",
    "        \n",
    "        # Random split between min and max\n",
    "        self.split_value = np.random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Split data\n",
    "        left_mask = col_data < self.split_value\n",
    "        X_left = X[left_mask]\n",
    "        X_right = X[~left_mask]\n",
    "        \n",
    "        # Recursively build left and right subtrees\n",
    "        self.left = IsolationTree(self.max_depth).fit(X_left, depth + 1)\n",
    "        self.right = IsolationTree(self.max_depth).fit(X_right, depth + 1)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def path_length(self, x, depth=0):\n",
    "        # If leaf node, return current depth\n",
    "        if self.split_feature is None:\n",
    "            return depth\n",
    "        \n",
    "        # Go left or right based on split\n",
    "        if x[self.split_feature] < self.split_value:\n",
    "            return self.left.path_length(x, depth + 1)\n",
    "        else:\n",
    "            return self.right.path_length(x, depth + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Isolation Forest Class\n",
    "\n",
    "An ensemble of isolation trees that combines multiple trees to detect anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationForest:\n",
    "    def __init__(self, n_trees=100, max_samples=256):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_samples = max_samples\n",
    "        self.trees = []\n",
    "        \n",
    "    def fit(self, X):\n",
    "        n_samples = len(X)\n",
    "        max_depth = int(np.ceil(np.log2(self.max_samples)))\n",
    "        \n",
    "        # Build multiple trees\n",
    "        for _ in range(self.n_trees):\n",
    "            # Sample random subset\n",
    "            sample_size = min(self.max_samples, n_samples)\n",
    "            sample_idx = np.random.choice(n_samples, sample_size, replace=False)\n",
    "            X_sample = X[sample_idx]\n",
    "            \n",
    "            # Build tree\n",
    "            tree = IsolationTree(max_depth)\n",
    "            tree.fit(X_sample)\n",
    "            self.trees.append(tree)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def anomaly_score(self, X):\n",
    "        # Average path length across all trees\n",
    "        avg_path_lengths = np.zeros(len(X))\n",
    "        \n",
    "        for x_idx, x in enumerate(X):\n",
    "            path_sum = sum(tree.path_length(x) for tree in self.trees)\n",
    "            avg_path_lengths[x_idx] = path_sum / self.n_trees\n",
    "        \n",
    "        # Normalize: shorter paths = higher anomaly score\n",
    "        # Using simplified scoring (0 to 1 range)\n",
    "        max_path = np.log2(self.max_samples)\n",
    "        scores = 2 ** (-avg_path_lengths / max_path)\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Sample Data\n",
    "\n",
    "Create a dataset with normal points and some anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate normal data (clustered around origin)\n",
    "X_normal = np.random.randn(300, 2)\n",
    "\n",
    "# Add some anomalies (scattered randomly)\n",
    "X_anomalies = np.random.uniform(-4, 4, (20, 2))\n",
    "\n",
    "# Combine datasets\n",
    "X = np.vstack([X_normal, X_anomalies])\n",
    "\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Normal samples: {len(X_normal)}\")\n",
    "print(f\"Anomaly samples: {len(X_anomalies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_normal[:, 0], X_normal[:, 1], alpha=0.6, label='Normal', s=30)\n",
    "plt.scatter(X_anomalies[:, 0], X_anomalies[:, 1], alpha=0.8, label='Anomalies', \n",
    "            s=100, marker='x', color='red', linewidths=2)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Dataset: Normal Points vs Anomalies')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "iso_forest = IsolationForest(n_trees=100, max_samples=256)\n",
    "iso_forest.fit(X)\n",
    "\n",
    "print(f\"Model trained with {iso_forest.n_trees} trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate Anomaly Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get anomaly scores for all points\n",
    "scores = iso_forest.anomaly_score(X)\n",
    "\n",
    "# Separate scores for normal and anomalous points\n",
    "normal_scores = scores[:300]\n",
    "anomaly_scores = scores[300:]\n",
    "\n",
    "print(f\"Normal points - Average score: {normal_scores.mean():.3f}\")\n",
    "print(f\"Normal points - Score range: [{normal_scores.min():.3f}, {normal_scores.max():.3f}]\")\n",
    "print()\n",
    "print(f\"Anomaly points - Average score: {anomaly_scores.mean():.3f}\")\n",
    "print(f\"Anomaly points - Score range: [{anomaly_scores.min():.3f}, {anomaly_scores.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Anomaly Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Score distribution\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(normal_scores, bins=30, alpha=0.6, label='Normal', color='blue')\n",
    "plt.hist(anomaly_scores, bins=30, alpha=0.6, label='Anomalies', color='red')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Anomaly Scores')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Scatter plot colored by anomaly score\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=scores, cmap='coolwarm', \n",
    "                      s=50, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "plt.colorbar(scatter, label='Anomaly Score')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Points Colored by Anomaly Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Identify Top Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of top 20 anomalies\n",
    "top_anomaly_indices = np.argsort(scores)[-20:]\n",
    "\n",
    "print(\"Top 20 anomalies (highest scores):\")\n",
    "for i, idx in enumerate(top_anomaly_indices[::-1], 1):\n",
    "    print(f\"{i:2d}. Index {idx:3d}: Score = {scores[idx]:.3f}, Point = {X[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some test points\n",
    "test_points = np.array([\n",
    "    [0.0, 0.0],      # Should be normal (at center)\n",
    "    [5.0, 5.0],      # Should be anomalous (far from center)\n",
    "    [0.5, -0.5],     # Should be normal (close to center)\n",
    "    [-4.0, 3.0]      # Should be anomalous (far from center)\n",
    "])\n",
    "\n",
    "# Score the test points\n",
    "test_scores = iso_forest.anomaly_score(test_points)\n",
    "\n",
    "print(\"Test point predictions:\")\n",
    "for i, (point, score) in enumerate(zip(test_points, test_scores), 1):\n",
    "    label = \"ANOMALY\" if score > 0.6 else \"NORMAL\"\n",
    "    print(f\"Point {i}: {point} -> Score: {score:.3f} ({label})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This simple implementation demonstrates the core concepts of Isolation Forest:\n",
    "\n",
    "- **Isolation Trees** use random splits to partition the data\n",
    "- **Path Length** measures how quickly a point gets isolated\n",
    "- **Anomalies** have shorter path lengths (easier to isolate)\n",
    "- **Ensemble** of trees provides robust scoring\n",
    "\n",
    "The algorithm works well because anomalies are rare and different from normal points, so random partitions isolate them quickly!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
